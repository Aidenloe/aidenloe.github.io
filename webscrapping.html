<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Aiden Loe" />


<title>Web Scrapping</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
}

</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Aiden Loe</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="about.html">About</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    R 4 Social Scientists
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">What is R?</li>
    <li>
      <a href="introToR.html">Intro to R</a>
    </li>
    <li>
      <a href="dataVisual.html">Data Visualisation</a>
    </li>
    <li>
      <a href="datawrangling.html">Data Wrangling</a>
    </li>
    <li>
      <a href="textAnalysis.html">Regular Expressions</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Big Data 4 Social Scientists
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">What is ML?</li>
    <li>
      <a href="introToML.html">Intro to ML</a>
    </li>
    <li>
      <a href="webscrapping.html">Web Scrapping</a>
    </li>
    <li>
      <a href="datamining.html">Data Mining</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    IRT 4 Social Scientists
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">What is IRT?</li>
    <li>
      <a href="introToIRT.html">Intro to IRT</a>
    </li>
    <li>
      <a href="testinfo.html">Test Information</a>
    </li>
    <li>
      <a href="irtplots.html">Plotting to IRT</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    CAT 4 Social Scientists
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">What is CAT?</li>
    <li>
      <a href="introToCAT.html">Intro to CAT</a>
    </li>
    <li>
      <a href="catSimulation.html">CAT simulation</a>
    </li>
  </ul>
</li>
<li>
  <a href="blog.html">Blog Post</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Web Scrapping</h1>
<h4 class="author"><em>Aiden Loe</em></h4>
<h4 class="date"><em>19 December, 2018</em></h4>

</div>


<div id="web-scrapping-part-1" class="section level1">
<h1><strong>Web Scrapping (Part 1)</strong></h1>
<p>Scrapping viewership is one area of web scrapping, but perhaps you might be interested in doing sentiment analysis on content.</p>
<p>So we want to extract the contents of the web pages rather than number of times someone viewed the web page.</p>
<div id="scrape-content-wiki" class="section level2">
<h2><strong>Scrape content (Wiki)</strong></h2>
<p>We will be using the <code>RCurl</code> and <code>XML</code> package to help us with the scrapping.</p>
<p>Let’s use the Eurovision_Song_Contest as an example.</p>
<p>The <code>XML</code> package has plenty functions that can allow us to scrape the data.</p>
<p>Usually we are extracting information based on the tags of the web pages.</p>
<pre class="r"><code>##### SCRAPPING CONTENT OFF WEBSITES ######
require(RCurl)
require(XML)
# XPath is a language for querying XML 
# //Select anywhere in the document
# /Select from root
# @select attributes. Used in [] brackets

#### Wikipedia Example ####
url &lt;- &quot;https://en.wikipedia.org/wiki/Eurovision_Song_Contest&quot;
txt = getURL(url) # get the URL html code

# parsing html code into readable format
PARSED &lt;- htmlParse(txt)

# Parsing code using tags
xpathSApply(PARSED, &quot;//h1&quot;)

# strops code and return content of the tag
xpathSApply(PARSED, &quot;//h1&quot;, xmlValue) # h1 tag
xpathSApply(PARSED, &quot;//h3&quot;, xmlValue) # h3 tag
xpathSApply(PARSED, &quot;//a[@href]&quot;) # a tag with href attribute


# Go to url 
# Highlight references
# right click, inspect element
# Search for tags
xpathSApply(PARSED, &quot;//span[@class=&#39;reference-text&#39;]&quot;,xmlValue) # parse notes and citations
xpathSApply(PARSED, &quot;//cite[@class=&#39;citation news&#39;]&quot;,xmlValue) # parse citation news
xpathSApply(PARSED, &quot;//span[@class=&#39;mw-headline&#39;]&quot;,xmlValue) # parse headlines
xpathSApply(PARSED, &quot;//p&quot;,xmlValue) # parsing contents in p tag
xpathSApply(PARSED, &quot;//cite[@class=&#39;citation news&#39;]/a/@href&quot;) # parse links under citation. xmlValue not needed. 
xpathSApply(PARSED, &quot;//p/a/@href&quot;) # parse href links under all p tags
xpathSApply(PARSED, &quot;//p/a/@*&quot;) # parse all atributes under all p tags

# Partial matches - subtle variations within or between pages. 
xpathSApply(PARSED, &quot;//cite[starts-with(@class, &#39;citation news&#39;)]&quot;,xmlValue) # parse citataion news that starts with..
xpathSApply(PARSED, &quot;//cite[contains(@class, &#39;citation news&#39;)]&quot;,xmlValue) # parse citataion news that contains.

# Parsing tree like structure
parsed&lt;-   htmlTreeParse(txt, asText = TRUE)</code></pre>
</div>
<div id="scrape-content-bbc" class="section level2">
<h2><strong>Scrape content (BBC)</strong></h2>
<p>When you know the structure of the data.</p>
<p>All you need to do is to find the correct function to scrape.</p>
<pre class="r"><code>##### BBC Example ####
url &lt;- &quot;https://www.bbc.co.uk/news/uk-england-london-46387998&quot;
url &lt;- &quot;https://www.bbc.co.uk/news/education-46382919&quot;
txt = getURL(url) # get the URL html code

# parsing html code into readable format
PARSED &lt;- htmlParse(txt)
xpathSApply(PARSED, &quot;//h1&quot;, xmlValue) # h1 tag
xpathSApply(PARSED, &quot;//p&quot;, xmlValue) # p tag
xpathSApply(PARSED, &quot;//p[@class=&#39;story-body__introduction&#39;]&quot;, xmlValue) # p tag body
xpathSApply(PARSED, &quot;//div[@class=&#39;date date--v2&#39;]&quot;,xmlValue) # date, only the first is enough
xpathSApply(PARSED, &quot;//meta[@name=&#39;OriginalPublicationDate&#39;]/@content&quot;) # sometimes there is meta data. </code></pre>
</div>
<div id="create-simple-bbc-scrapper" class="section level2">
<h2><strong>Create simple BBC scrapper</strong></h2>
<p>Sometimes, creating a function will make your life better and make your script look simpler.</p>
<pre class="r"><code>##### Create simple BBC scrapper #####
# scrape title, date and content
BBCscrapper1&lt;- function(url){
  txt = getURL(url) # get the URL html code
  PARSED &lt;- htmlParse(txt) # Parse code into readable format
  title &lt;- xpathSApply(PARSED, &quot;//h1&quot;, xmlValue) # h1 tag
  paragraph &lt;- xpathSApply(PARSED, &quot;//p&quot;, xmlValue) # p tag
  date &lt;- xpathSApply(PARSED, &quot;//div[@class=&#39;date date--v2&#39;]&quot;,xmlValue) # date, only the first is enough
  date &lt;- date[1]
  return(cbind(title,date))
  #return(as.matrix(c(title,date)))
}


# Use function that was just created. 
BBCscrapper1(&quot;https://www.bbc.co.uk/news/education-46382919&quot;)</code></pre>
<pre><code>##      title                                                         
## [1,] &quot;Ed Farmer: Expel students who defy initiations ban, says dad&quot;
##      date              
## [1,] &quot;29 November 2018&quot;</code></pre>
</div>
<div id="keeping-it-neat" class="section level2">
<h2><strong>Keeping it neat</strong></h2>
<p>Using the <code>plyr</code> package helps to arrange the data in an organised way.</p>
<pre class="r"><code>## Putting the title and date into a dataframe
require(plyr)
#url
url&lt;- c(&quot;https://www.bbc.co.uk/news/uk-england-london-46387998&quot;, &quot;https://www.bbc.co.uk/news/education-46382919&quot;)
## ldply: For each element of a list, apply function then combine results into a data frame
#put into a dataframe
ldply(url,BBCscrapper1)</code></pre>
<pre><code>##                                                          title
## 1              Man murdered widow, 80, in London allotment row
## 2 Ed Farmer: Expel students who defy initiations ban, says dad
##               date
## 1 29 November 2018
## 2 29 November 2018</code></pre>
</div>
</div>
<div id="web-scrapping-part-2" class="section level1">
<h1><strong>Web Scrapping (Part 2)</strong></h1>
<p>This example below is taken from code kindly written by David stillwell.</p>
<p>Some editing has been made to the original code.</p>
<div id="scrape-from-wiki-tables" class="section level2">
<h2><strong>Scrape from Wiki tables</strong></h2>
<p>You have learned how to scrape viewership on wikipedia and content on web pages.</p>
<p>This section is about scrapping data tables online.</p>
<pre class="r"><code># Install the packages that you don&#39;t have first. 
library(&quot;RCurl&quot;) # Good package for getting things from URLs, including https
library(&quot;XML&quot;) # Has a good function for parsing HTML data
library(&quot;rvest&quot;) #another package that is good for web scraping. We use it in the Wikipedia example

#####################
### Get a table of data from Wikipedia
## all of this happens because of the read_html function in the rvest package
# First, grab the page source
us_states = read_html(&quot;https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_population&quot;) %&gt;% # piping
  # then extract the first node with class of wikitable
  html_node(&quot;.wikitable&quot;) %&gt;% 
  # then convert the HTML table into a data frame
  html_table()</code></pre>
</div>
<div id="scrape-from-online-tables" class="section level2">
<h2><strong>Scrape from online tables</strong></h2>
<p>If we can have two data tables that have at least one column with the same name, then we can merge them together.</p>
<p>The main idea is to link the data together to run simple analysis.</p>
<p>In this case we can get data about <a href="http://apps.saferoutesinfo.org/legislation_funding/state_apportionment.cfm">funding</a> given to various US states to support building infrastructure to improve students’ ability to walk and bike to school.</p>
<pre class="r"><code>######################
url &lt;- &quot;http://apps.saferoutesinfo.org/legislation_funding/state_apportionment.cfm&quot;
funding&lt;-htmlParse(url) #get the data

# find the table on the page and read it into a list object
funding&lt;- XML::readHTMLTable(funding,stringsAsFactors = FALSE)

funding.df &lt;- do.call(&quot;rbind&quot;, funding) #flatten data
# Contain empty spaces previously.
colnames(funding.df)[1]&lt;- c(&quot;State&quot;) # shorten colname to just State. 

# Match up the tables by State/Territory names
# so we have two data frames, x and y, and we&#39;re setting the columns we want to do the matching on by setting by.x and by.y
mydata = merge(us_states, funding.df, by.x=&quot;State, federal district, or territory&quot;, by.y=&quot;State&quot;)
# it looks pretty good, but note that we&#39;re down to 50 US States, because the others didn&#39;t match up by name
# e.g. &quot;District of Columbia&quot; in the us_states data, doesn&#39;t match &quot;Dist. of Col.&quot; in the funding data

#Replace the total spend column name with a name that&#39;s easier to use.
colnames(mydata)[18] = &quot;total_spend&quot;

#  We need to remove commas so that R can treat it as a number.
mydata[,&quot;Population estimate, July 1, 2017[4]&quot;] = gsub(&quot;,&quot;, &quot;&quot;, mydata[,&quot;Population estimate, July 1, 2017[4]&quot;]) 
mydata[,&quot;Population estimate, July 1, 2017[4]&quot;] = as.numeric(mydata[,&quot;Population estimate, July 1, 2017[4]&quot;]) #this converts it to a number data type

# Now we have to do the same thing with the funding totals, which are in a format like this: $17,309,568
mydata[,&quot;total_spend&quot;] = gsub(&quot;,&quot;, &quot;&quot;, mydata[,&quot;total_spend&quot;]) #this removes all commas
mydata[,&quot;total_spend&quot;] = gsub(&quot;\\$&quot;, &quot;&quot;, mydata[,&quot;total_spend&quot;]) #this removes all dollar signs. We have a \\ because the dollar sign is a special character.
mydata[,&quot;total_spend&quot;] = as.numeric(mydata[,&quot;total_spend&quot;]) #this converts it to a number data type

# Now we can do the plotting
options(scipen=9999) #stop it showing scientific notation
plot(mydata[,&quot;Population estimate, July 1, 2017[4]&quot;], mydata[,&quot;total_spend&quot;])</code></pre>
<p><img src="webscrapping_files/figure-html/Scrape%20Table%20(non-wiki)-1.png" width="672" /></p>
<pre class="r"><code>## What&#39;s does the correlation between state funding and state population look like?
cor(mydata[,&quot;Population estimate, July 1, 2017[4]&quot;], mydata[,&quot;total_spend&quot;]) # 0.9924265 - big correlation!</code></pre>
<pre><code>## [1] 0.9885666</code></pre>
</div>
<div id="plot-funding-data-on-map" class="section level2">
<h2><strong>Plot funding data on map</strong></h2>
<p>Perhaps it might be more interesting to see how the data is like on a map.</p>
<p>We can utilise <code>map_data</code> function in the <code>ggplot</code> package to help us with that.</p>
<p>Again, with a bit of data manipulation, we can merge the data table that contains the longitude and latitude information together with the funding data across different states.</p>
<pre class="r"><code>require(ggplot2)
all_states &lt;- map_data(&quot;state&quot;) # states
colnames(mydata)[1] &lt;- &quot;state&quot; # rename to states
mydata$state &lt;- tolower(mydata$state) #set all to lower case
Total &lt;- merge(all_states, mydata, by.x=&quot;region&quot;, by.y = &#39;state&#39;) # merge data
# we have data for delaware but not lat, long data in the maps
i &lt;- which(!unique(all_states$region) %in% mydata$state) 

# Plot data
ggplot() + 
  geom_polygon(data=Total, aes(x=long, y=lat, group = group, fill=Total$total_spend),colour=&quot;white&quot;) + 
  scale_fill_continuous(low = &quot;thistle2&quot;, high = &quot;darkred&quot;, guide=&quot;colorbar&quot;) + 
  theme_bw()  + 
  labs(fill = &quot;Funding for School&quot; ,title = &quot;Funding for School between 2005 to 2012&quot;, x=&quot;&quot;, y=&quot;&quot;) + 
  scale_y_continuous(breaks=c()) +
  scale_x_continuous(breaks=c()) +
  theme(panel.border =  element_blank(),
        text = element_text(size=20))</code></pre>
<p><img src="webscrapping_files/figure-html/Plot%20on%20Map-1.png" width="1728" /></p>
</div>
</div>
<div id="web-scrapping-part-3" class="section level1">
<h1><strong>Web Scrapping (Part 3)</strong></h1>
<div id="scrape-from-discussion-forums" class="section level2">
<h2><strong>Scrape from discussion forums</strong></h2>
<p>Coming soon..</p>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-98916204-1', 'auto');
  ga('send', 'pageview');

</script>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
